{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525a372-15e1-4ce7-b62e-2555acf187bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name:Manoj Kumar G\n",
    "Reg no:212222230078"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76df37e7-ee1e-43aa-971b-ec2b4412e242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Using cached torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
      "Using cached torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7459d790-35a4-4ac5-a544-6c4d01d1c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c146eb64-9045-4fb4-919b-4d78b6b00487",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f7c479e-49f1-4446-9cc9-dc14ce9e4175",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c573801-aa07-48fa-8300-50b70e486a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5ce76ba-9c58-43ea-bff5-b98876f9d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(inputs, noise_factor=0.5):\n",
    "    noisy = inputs + noise_factor * torch.randn_like(inputs)\n",
    "    return torch.clamp(noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05dee8dd-6535-4209-ac58-1b01ab080fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Include your code here\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # (B, 16, 28, 28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                          # (B, 16, 14, 14)\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1),  # (B, 8, 14, 14)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)                           # (B, 8, 7, 7)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, kernel_size=2, stride=2),  # (B, 16, 14, 14)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=2, stride=2),  # (B, 1, 28, 28)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Include your code here\n",
    "         x = self.encoder(x)\n",
    "         x = self.decoder(x)\n",
    "         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6290e600-6b4a-457d-84e0-119699e085e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenoisingAutoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef16bc4f-d6b3-4c64-abff-049fd1ecc0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             160\n",
      "              ReLU-2           [-1, 16, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 16, 14, 14]               0\n",
      "            Conv2d-4            [-1, 8, 14, 14]           1,160\n",
      "              ReLU-5            [-1, 8, 14, 14]               0\n",
      "         MaxPool2d-6              [-1, 8, 7, 7]               0\n",
      "   ConvTranspose2d-7           [-1, 16, 14, 14]             528\n",
      "              ReLU-8           [-1, 16, 14, 14]               0\n",
      "   ConvTranspose2d-9            [-1, 1, 28, 28]              65\n",
      "          Sigmoid-10            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 1,913\n",
      "Trainable params: 1,913\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.30\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "740cb326-590a-4409-9d74-77b0b2564c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, epochs=5):\n",
    "    # Include your code here\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "            noisy_images = add_noise(images).to(device)\n",
    "\n",
    "            outputs = model(noisy_images)\n",
    "            loss = criterion(outputs, images)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73d447b1-bde5-4644-8ca2-d395a2a1131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_denoising(model, loader, num_images=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "            noisy_images = add_noise(images).to(device)\n",
    "            outputs = model(noisy_images)\n",
    "            break\n",
    "\n",
    "    images = images.cpu().numpy()\n",
    "    noisy_images = noisy_images.cpu().numpy()\n",
    "    outputs = outputs.cpu().numpy()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    for i in range(num_images):\n",
    "        # Original\n",
    "        ax = plt.subplot(3, num_images, i + 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "        ax.set_title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Noisy\n",
    "        ax = plt.subplot(3, num_images, i + 1 + num_images)\n",
    "        plt.imshow(noisy_images[i].squeeze(), cmap='gray')\n",
    "        ax.set_title(\"Noisy\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Denoised\n",
    "        ax = plt.subplot(3, num_images, i + 1 + 2 * num_images)\n",
    "        plt.imshow(outputs[i].squeeze(), cmap='gray')\n",
    "        ax.set_title(\"Denoised\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb44322-a680-4cab-88fe-80ffb5f04764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, _ in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f9a983-53a5-4f26-91ea-9c01e1eb044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded.view(x.size(0), 1, 28, 28)\n",
    "\n",
    "model = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "244f1015-5457-496a-8ebf-378273a2fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transform: convert image to tensor + normalize (0â€“1)\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Load MNIST training set\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Load MNIST test set\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8443aa5-cb2a-45ca-b6c1-576aceddc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15f7891d-5e49-46cc-b5d9-2eda40921219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def visualize_denoising(model, data_loader, num_images=5):\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of images\n",
    "    images, _ = next(iter(data_loader))\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "    \n",
    "    # Show results\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Original\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(images[i].squeeze().cpu(), cmap=\"gray\")\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        # Reconstructed\n",
    "        plt.subplot(2, num_images, num_images + i + 1)\n",
    "        plt.imshow(outputs[i].squeeze().cpu(), cmap=\"gray\")\n",
    "        plt.title(\"Reconstructed\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99938db7-1436-44c1-a7d0-a3ce0f11cc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0045\n",
      "Epoch [2/5], Loss: 0.0041\n",
      "Epoch [3/5], Loss: 0.0038\n",
      "Epoch [4/5], Loss: 0.0036\n",
      "Epoch [5/5], Loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, criterion, optimizer, epochs=5)\n",
    "visualize_denoising(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09165afb-0c35-48b5-b73d-d707384d5171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
